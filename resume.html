<html>
<head>
<!-- Template stolen from Matt Cutts, who apparently stole it from Paul Haahr -->
<meta http-equiv="content-type" content="text/html; charset=UTF-8"></meta>
<title>Dan Vanderkam: Google Resume
</title>
  <meta NAME="Author" CONTENT="danvk@google.com (Dan Vanderkam)">
  <style type="text/css">
    <!--
    body {
      font-family: 'Lucida Grande', Verdana, Arial, Sans-Serif;
      font-size: 85%;
      line-height: 1.3em;
      background-color: white;
      margin-left: 0.75in;
      margin-right: 0.5in;
      max-width: 900px;
    }
    h1, h2, h3, h4, h5, h6 {
      color: #663300;
    }
    h1, h2 {
      margin-left: -0.5in;
      font-weight: bold;
    }
    h1 {
      font-size: 180%;
    }
    h2 {
      font-size: 120%;
    }
    h3 {
      margin-left: -0.25in;
    }
    p, ol, ul {
      margin-top: .75em;
      margin-bottom: 1em;
    }
    .dense {
      margin-top: 0ex;
      margin-bottom: 0ex;
    }
    .stacked {
      margin-bottom: 0ex;
    }
    .unindented {
      margin-left: -0.25in;
    }
    .long {
      margin-top: 1em;
      margin-bottom: 1em;
    }
    .loose li {
      padding-bottom: 5px;
    }
    .loose li li {
      padding-bottom: 1px;
    }
    -->
  </style>
<script> 
<!--
function _setEltDisplay(a,c){if(!document.getElementById){return false}var b=document.getElementById(a);if(b){b.style.display=c}return false}
function _toggleSection(a){var c=a.id.indexOf("_");if(c==-1){return false}var b="cp"+a.id.substring(c);var d="cq"+a.id.substring(c);if(a.innerHTML.search("http://www.google.com/images/triangle.gif")!=-1){_setEltDisplay(b,"");_setEltDisplay(d,"none");a.innerHTML="<img src=http://www.google.com/images/opentriangle.gif border=0 height=11 width=11>"}else{_setEltDisplay(b,"none");_setEltDisplay(d,"");a.innerHTML="<img src=http://www.google.com/images/triangle.gif border=0 height=11 width=11>"}return false}
;
//-->
</script> 

</head>

<body>
<h1>Dan Vanderkam</h1>

<a href="mailto:danvdk@google.com">danvdk@gmail.com</a>

<h2>Hammer Lab (April 28, 2014–)</h2>

<p><a href="http://www.hammerlab.org/">Hammer Lab</a> is a software lab within the <a href="https://icahn.mssm.edu/departments-and-institutes/genomics">Icahn Institute</a> at <a href="https://icahn.mssm.edu/">Mount Sinai</a> in NYC.</p>

<p>I've worked primarily on visualizations, frontend tooling and software development processes.</p>

<ul>
  <li><a href="https://github.com/hammerlab/pileup.js/">pileup.js</a>
  <p>pileup.js is an interactive genome explorer which can be embedded within
  web pages. It was built from scratch using the latest (c. 2015) web
  technologies: ES2015, React, Flow, Babel, Browserify, Promises and Mocha.
  Read more in <a href="http://www.hammerlab.org/2015/06/19/introducing-pileup-js-a-browser-based-genome-viewer/">this
blog post</a> or <a href="http://www.hammerlab.org/pileup/">try a demo</a>.
  </p>

  <li><a href="https://github.com/hammerlab/cycledash/">Cycledash</a>
  <p>I was one of the primary developers for Cycledash, a tool for managing
  collections of genome data. This work led to the development of pileup.js.
  See the <a href="http://www.hammerlab.org/2015/01/28/introducing-cycledash-0-0-0/">blog
  post</a> introducing it.
  </p>

  <li>Blogging and Speeches</li>
  <p>I wrote extensively about my work at Hammer Lab and spoke at PyCon in
  2015.<br>
  See a <a href="http://www.danvk.org/2015/10/21/hammerlab-posts.html">roundup of my
  posts</a> and a <a href="https://www.youtube.com/watch?v=jUUTqgzNR3M">video</a>
  of <a href="https://us.pycon.org/2015/schedule/presentation/395/">my talk at
  PyCon</a>.
  </p>
</ul>

<h2>Google (August 14, 2006–April 25, 2014)</h2>

<p>I was as a Software Engineer at Google for approximately eight years. I
worked primarily in Search: ranking, features and projects relating to search
logs analysis.</p>

<p><i>(click on a triangle to see details about a project)</i></p>

<!--
<i>Each accomplishment should include the dates that you worked on the
project, a description of the project, participants, your role in the
project, the engineering challenge, and the impact of the project on
the company.</i>
-->
<h3 class="dense"><img src=http://www.google.com/images/opentriangle.gif width=11 height=11 border=0></a>
  TL, Tufte Team</h3>
<small>(August 2012 - <i>present</i>)</small>
<div style="max-width: 800px;">
  <p>While on sabbatical in 2012, I got an offer to TL a new team in NYC working
  on Search Visualizations. Over the past 18 months, I've helped shaped the team's
  mission as it's grown from one engineer to nine, gone through three manager
  changes and launched its first five features.</p>
<ul>

  <li><b>Finance Answer Card</b><br>
  Demo: <a href="https://www.google.com/search?q=GOOG">GOOG</a> (mobile/tablet)<p>

  <p>The Finance Answer Card is a major update to the Finance Onebox, bringing
  a cleaner style, an interactive chart and more relevant attributes. I pushed
  to get this project staffed and approved. My main technical contributions
  were designing and implementing the interactions.</p>
  <br>

  <li><b>Statistics Knowledge Panel</b><br>
  Demo: <a href="https://www.google.com/search?q=life+expectancy+south+africa">life
  expectancy south africa</a><p>

  <p>The Statistics Knowledge Panel shows interactive charts for Public Data
  queries (population, life expectancy, GDP, &hellip;). As the first interactive
  chart on the Search Results Page, it helped blaze the trail for more
  interactive features to come. It was <a
    href="http://www.youtube.com/watch?v=9pmPa_KxsAM#at=6853">featured</a> in
  the keynote at Google I/O!
  My group built the charting tool and did lots of the plumbing,
  My personal contributions mainly involved the
  design and implementation of the chart.</p>
  <br>

  <li><b>Fact Comparisons</b><br>
  Demo: <a href="https://www.google.com/search?q=brad+pitt+height">brad pitt
  height</a>

  <p>The Fact Comparisons feature contextualizes the answers to questions like
  "how tall is mount everest?" by showing related facts under the answer to the
  main question. It encourages exploration by adding facts to the Carousel.</p>

  <p>I participated in the (extended) design discussions which led to the
  feature, built the initial prototypes and coordinated the implementation and
  launch of the finished feature.</p>

  <br>

  <li><b>Entity Comparisons</b><br>
  Demo: <a href="https://www.google.com/search?q=mars+vs+jupiter">mars vs
  jupiter</a>

  <p>I
  helped to coordinate the initial division of labor and a path to launch in a
  tight time frame for an external press event. My
  technical contributions included running the Quality evaluation and latency
  testing.</p>
  <br>

  <li><b>March Madness Onebox</b><br>
  In January 2013 I proposed a Brackets onebox for NYC Search Demo Days. The
  project drew enough interest that I pursued it as a real project.
  Working under extremely tight external
  deadlines, we launched within a day of the tournament field being announced.
  The feature was a great success, getting <a
  href="https://contour.corp.google.com/#view/14159">30M views in
  three weeks</a> and earning
  lurid coverage from <a
  href="http://techcrunch.com/2013/03/19/google-march-madness-bracket/">TechCrunch</a>,
  <a
  href="http://searchengineland.com/march-madness-bracket-in-google-search-results-152319">Search
  Engine Land</a> and <a
  href="http://www.avc.com/a_vc/2013/03/fun-friday-march-madness.html">Fred
  Wilson</a>.
  <br><br>

</ul>
</div>

<h3 class="dense"><a id="t_correlate" onClick="return _toggleSection(this)"
    style="padding:0 2px 0 2px;cursor:hand;cursor:pointer;text-decoration:none;"
    href="#"><img src=http://www.google.com/images/triangle.gif width=11 height=11 border=0></a>
  Google Correlate (aka Mittens)</h3>
<small>(October 2010 - December 2011)</small>
<div id="cq_correlate" style="">
<ul>
  <li>Built an early proof-of-concept demo
  <li>Designed large portions of our infrastructure
  <li>Extensive exploration of approximate/exact Nearest Neighbors search
  <li>Streamlined and narrowed the vision for our product
  <li>Search by Drawing feature
  <li>Launch and general support
</ul>

<p>Correlate Papers:
<ul>
  <li><a href="https://www.google.com/trends/correlate/whitepaper.pdf">Google Correlate Whitepaper</a>, 
    Matt Mohebbi, Dan Vanderkam, Julia Kodysh, Rob Schonberger, Hyunyoung Choi &amp; Sanjiv Kumar
  <li><a href="https://www.google.com/trends/correlate/nnsearch.pdf">Nearest Neighbor Search in Google Correlate</a>,
    Dan Vanderkam, Robert Schonberger, Henry Rowley, Sanjiv Kumar
</ul>
</div>

<div id="cp_correlate" style="max-width: 800px; display: none;">
<ul>
  <li><b>Built an early proof-of-concept demo</b><br/>
  The original "mittens" demo
  was built by <a href="http://who/dougb">Doug Beeferman</a> in 2007. In 2009,
  Jeremy Ginsberg revived something like it using the GeoHistories. I realized
  that, if properly generalized, this demo could include the correlated events
  technique that we used to build Google Flu Trends. I built out a demo along
  these lines in some 20% time in late 2009. This demo lent credence to the
  idea of a mittens product, and some of the libraries I built remain in use in
  Google Correlate today.
  <br><br>

  <li><b>Designed large portions of our infrastructure</b><br/>
  I started
  full-time work on Mittens in October 2010. At the outset, <a
    href="http://who/robsc">Rob Schonberger</a>, <a
    href="http://who/mmohebbi">Matt Mohebbi</a> and I worked out a new design
  for mittens which featured a three-layer stack with clean separation between all layers: 
  frontend, service and ScaM backend. (The ScaM backend is a piece of
  infrastructure shared between groups) I implemented or code reviewed all of
  this architecture, which remains the system that we use today as the Google
  Correlate backend.
  <br><br>

  <li><b>Extensive exploration of approximate/exact Nearest Neighbors
    search</b><br/>
  At its core, Google Correlate (mittens) is an application of nearest
  neighbors search. The details of the mapping are described <a
    href="https://docs.google.com/a/google.com/document/d/1Wg15WjbJ8kR5tTIUzefwM_J4OGNc1WO2gw18K4Jo3po/edit?hl=en_US">here</a>.
  Some details of my explorations are <a
    href="https://docs.google.com/a/google.com/document/d/1ylfGfxbG21MgXBp1IdR42GFRNWQKuCxRpxInt_DfXV8/edit?authkey=COvL7pIG&hl=en_US&authkey=COvL7pIG">here</a>.
  In the end, I worked with the <a href="http://go/scam">scam</a> team to
  develop a new algorithm which achieved 99% precision and something like a 100x
  speedup.
  <br><br>

  <li><b>Streamlined and narrowed the vision for our product</b><br/>
  As important
  as what you do is what you don't do. In the run-up to our launch, I honed in
  on a set of features which we did need to launch (US States and US Weekly
  search, n-grams) and features which we did not need (modeling, international,
  a coherent update pipeline). This allowed us to ship a compelling product
  on-time.
  <br><br>

  <li><b>Search by Drawing feature</b><br/>
  The <a href="http://www.google.com/trends/correlate/draw">Search by
    Drawing</a> feature has proved to be one of the most popular,
  easily-accessible parts of Google Correlate. I implemented the drawing tool
  for a <a href="http://go/beeranddemos">Beer and Demos</a> demo. It quickly
  became our tool of choice for explaining what Correlate did (not an easy
  task!), and I pushed to get it into the initial launch. It has remained one of
  the most popular features of Correlate. Three months after launch, it hit the
  <a href="http://news.ycombinator.com/item?id=2953900">top of Hacker News</a>
  and <a href="http://www.reddit.com/r/technology/comments/k2j1e/google_correlate_by_drawing_actual_drawing/">reddit</a> in its own right, sending &gt;200k new visitors
  to Correlate over two days.
  <br><br>

  <li><b>Launch and general support</b><br/>
  Following our launch, I developed a
  lightweight sanity check which now forms the core of our monitoring system. I
  also owned and operated our <a href="http://go/mittenspipe">data update
    pipeline</a>.
  <br><br>

  <i>At the end of 2011, Google Correlate was transitioned to the Tel Aviv
    office.</i>

</ul><div style="clear:both; padding-bottom: 0.25em;"></div>
</div>

<!--
<div class="day"><div class="body">
-->
<div style="clear:both;"></div>

<h3 class=dense><a id="t_flutrends" onClick="return _toggleSection(this)"
    style="padding:0 2px 0 2px;cursor:hand;cursor:pointer;text-decoration:none;"
    href="#"><img src=http://www.google.com/images/triangle.gif width=11 height=11 border=0></a> Google Flu Trends</h3>
<small>(January 2009 - October 2009)</small>

<p>
In early 2009, I transitioned from webspam to the yala team, which is best known
for producing <a href="http://www.google.org/flutrends/">Google Flu Trends</a>.
</p>

<div id="cq_flutrends" style="">
  <ul>
    <li>Flu Trends International
    <li>Flu Trends Australia/New Zealand
    <li>Emergency Launch: Google Flu Trends for Mexico
    <li>GeoHistory Infrastructure
  </ul>
</div>

<div id="cp_flutrends" style="display:none;">

<h4 class=dense>Flu Trends International</h4>
<small>(June 2009 - October 2009)</small>
<p>
After the emergence of H1N1 in April 2009, health agencies are keenly interested
in seeing what happens during the 2009-2010 northern hemisphere flu season. We
attempted to ride this wave of interest with a big international launch prior to
the onset of flu season. We launched on October 8 in 20 countries (8 with
regional estimates) and in 37 languages.</p>

<p>My primary contributions were:
<ul class=dense>
  <li>At <a href="http://who/craignm">craignm</a>'s suggestion, built a global
  flu dashboard with our latest updates for each country. This has become a
  guide for much of our work &mdash; it shows us which countries we are likely to
  produce good models for.</li>

  <li>Developed a system for doing our analysis work in Matlab. This has allowed
  us to iterate on modeling techniques far more quickly than we were able to
  with the old approach of C++ and shell scripts.</li>

  <li>New modeling techniques: ran experiments to test the efficacy of (1)
  translating English query terms into other languages and (2) expanding
  existing query lists using regular expressions. These were both successful and
  are likely to be used in the final product.</li>

  <li>Extensive modeling work on individual countries. Have looked in detail at:
  Austria, Canada, France, Italy, South Africa, Spain, Sweden, Taiwan, Germany
  and Japan.</li>

  <li>Introduced <a
    href="http://epitaphs.prom.corp.google.com/googlers/ghs/">ghs</a> and <a
    href="http://who/tmorse">tmorse</a> to the Flu Trends frontend. They have
  been internationalizing our product and building a site that can handle 20+
  countries.</li>
</ul>
</p>

<h4 class=dense>Flu Trends Australia/New Zealand</h4>
<small>(May-June 2009)</small>

<p>
After the swine flu scare of April 2009, our team decided to focus our energies
on a launch in Australia and New Zealand in advance of the southern hemisphere
flu season. Along with <a href="http://who/mmohebbi">Matt Mohebbi</a>, I did the
engineering work behind this <a
  href="http://blog.google.org/2009/06/google-flu-trends-for-australia-and-new.html">launch</a>
and even managed to get my name on the official google.org blog post!
</p>
<p>
My primary contributions were:
<ul class="dense">
  <li>Built our flu model for New Zealand.
  <li>Built a new production pipeline which could handle multiple
  countries/languages. This amounted to turning the horrendous hack from the
  lightning-fast Mexico launch into something we could look at without gagging.
  <li>Designed and implemented a system for rendering small "mini maps" of
  regional flu activity in each country for our home page. This was not
  initially part of the launch plan, but was well-received after I demonstrated
  its feasability.
</ul>
</p>

<h4 class=dense>Emergency Launch: Google Flu Trends for Mexico</h4>
<small>(April 2009)</small>
<p>
When the first reports of H1N1 Swine Flu emerged in late April, CDC contacted
our team to learn whether we could help them determine the spread of the
disease. I built a day-of-week model to produce smooth daily estimates for the
CDC (external Flu Trends estimates are only weekly). Amazingly enough, our
briefings were the only daily updates CDC was receiving about this emerging
pandemic.
</p>
<p>
<a href="http://who/jeremyg">Jeremy Ginsberg</a> mentioned the idea of
launching Flu Trends for Mexico to the OC, which wholeheartedly approved the
idea. Though we hadn't yet developed a methodology for tracking flu in places
which lack historic truth data, we scrambled and rapidly iterated through a few
ideas until we discovered a method of using existing non-Spanish queries as
proxy truth data, so we could then find more popular Spanish queries which
historically correlated with this proxy truth set.
</p>
<p>
Because CDC found our data to be useful, we decided to quickly develop and
launch a public version of our data and internationalize the product months
ahead of schedule. 47 sleep-deprived hours later, we launched Mexico's first and
only near-real time influenza surveillance system; public health officials and
media outlets worldwide were enthusiastic about the launch. The <i>New York
  Times</i> <a
  href="http://www.nytimes.com/2009/05/04/technology/internet/04link.html">helpfully
  noted the difference</a> between our smooth estimates and the huge spikes in
panicked tweets and searches for <code>[swine flu]</code>.
</p>
<p>
My primary contributions were:
<ul class="dense">
  <li>Produced daily estimates for CDC
  <li>Built an independent pipeline for producing Mexico estimates and web page.
  <li>Hacked in support for Spanish language pages on our site.
</ul>
</p>

<h4 class=dense>GeoHistory Infrastructure</h4>
<small>(Jan 2009-<i>present</i>)</small>

<p>A <a href="http://wiki/Main/GeoHistories">GeoHistory</a> is a record of how
often an event occurred at every place and every time. In the Yala group, we
maintain GeoHistories of every query that has ever been performed. Since joining
the group in January 2009, I have found my niche maintaining and building on
this data store.

<p>
Some highlights:
<ul class="dense">
  <li>Created the <a href="http://geohistory/">GeoHistory Server</a>, which
  allows exploration of the <a
    href="http://wiki/Main/GeoHistories">GeoHistory</a> store in the
  browser.</li>

  <li>Created a distilled version of the GeoHistories and <a
    href="http://wiki.corp.google.com/Main/GeoHistoryUserGuide">extensive</a> <a
    href="http://wiki.corp.google.com/Main/SearchQualityGeoHistories">documentation</a>
  that is accessible to all Search Quality engineers. Along with Rajan Patel, I
  used this data to perform a number of interesting analysis, e.g.
    <ul>
      <li><a href="https://qwiki/pages/viewpage.action?pageId=10855479">What
        fraction of our daily queries have we never seen before?</a></li>
      <li><a href="https://qwiki/pages/viewpage.action?pageId=10856642">How much
        can we infer about the future querystream from the past?</a></li>
    </ul>
    This data is already being used by <a href="http://who/aorban">Andras
      Orban</a> to improve freshness on cyclic queries, and we hope that it will
    be used even more in the future.
  </li>

  <li>Significant refactoring of the GeoHistory infrastructure to be less
  memory-intensive.</li>

  <li>Gave a <a
    href="https://video.google.com/a/?pli=1#%2FPlay%2FcontentId%3D4145ea9360443037">tech
    talk</a> about the GeoHistories in Mountain View in 2011.</a>

  <li>Created tools for converting GeoHistories to Matlab format and a library
  for doing analysis in Matlab. This has dramatically improved our ability to
  iterate on modeling techniques.</li>
</ul>
</p>
</div>

<h3 class=dense><a id="t_webspam" onClick="return _toggleSection(this)" style="padding:0 2px 0 2px;cursor:hand;cursor:pointer;text-decoration:none;" href="#"><img src=http://www.google.com/images/triangle.gif width=11 height=11 border=0></a> Webspam</h3>
<small>(August 2006 - March 2009)</small>

<p>For my first 2.5 years at Google, I worked in the <a href="">webspam</a> group
under <a href="http://who/matt">Matt Cutts</a>.</p>

<div id="cq_webspam" style="">
  <ul>
    <li>Indyrank
    <li>Spam Metrics
    <li>High Velocity Spam
    <li>Surfer
    <li>New Domains Feed
    <li>Commercial Queries
  </ul>
</div>

<div id="cp_webspam" style="display:none;">
<h4 class=dense>Indyrank</h4>
<small>(August 2007 - March 2009)</small>

<p>
In Q3 2007, I took over maintenance of Indyranks from <a
  href="http://who/mattr">Matt Rosencrantz</a>. Beginning in Q4 2007, I did a
detailed statistical analysis of the Indyrank flow algorithm and developed a
simplified, non-iterative version called Simplified Indyrank (SIR). SIR
launched in Q2 2008 and has been in production ever since.
</p>

<p>The switch to Simplified Indyrank greatly.. simplified the production of
indyranks, allowing for faster iteration time on experiments and new features.
It has also allowed new Indyranks to be pushed much more frequently. When I
took over Indyrank, pushes occurred once or twice per quarter. Now they occur
every 1&ndash;2 weeks.</p>

<h4 class=dense>Spam Metrics</h4>
<small>(November 2006 - March 2009)</small>

<p>
Took over the spam metrics pipeline from <a href="http://who/greggrothaus">Greg
  Grothaus</a>. This involves
monitoring several daily cron jobs and ensuring that our spam metrics don't
get too many days behind. Changes that have occurred while I've been at the
helm include:
  <ul>
    <li>Turning off SpamCents to double the number of SpamClicks ratings.</li>
    <li>New graphs on <a href="http://webspamdash/">webspamdash</a>: Spamdash
    Lag, Velocity, Squipex Backlog, Spam by Source Corpus and Tipex Penalty
    Labels.</li>
    <li>Developed the <a href="http://www/~danvk/dg/">Dynamic Graphs</a>
    JavaScript library to aid in visualization (see below). This has allowed
    analysis of changes in spam rate from the spam dashboard itself.</li>
  </ul>
</p>

<p>In Q3 2008, I redesigned the SpamCents pipeline to save more information
about the clicks we were sampling and the documents we were rating. I used this
data to build the <a href="http://go/spamgeist2">geist server</a>, which allows
the exploration of numerous signals using SpamCents data. I gave a <a
  href="https://docs.google.com/a/google.com/Presentation?docid=cd3zws38_15c6bq7hf6&hl=en">talk</a> on the geist server at the August 5 and September 16 webspam
meetings.</p>

<h4 class=dense>High Velocity Spam</h4>
<small>(January 2008 - June 2008)</small>
<p>At the start of 2008, I did some analysis of URL ages at the time they were
clicked using SpamCents URLs. I discovered that "fresh" URLs (less than a week
in the index) were significantly more likely to be spam than older URLs. This
discovery laid the basis for the <a href="http://go/hvsp">High Velocity
  Spam</a> project, which tackles fresh spam using techniques specially
designed for new pages.</p>

<p>As the project progressed, I created a pipeline to collect information on
quarantined URLs from gws logs, developed a dashboard on <a
  href="http://webspamdash#velocity">webspamdash</a> to track our effects and
provided general advice/feedback about design decisions affecting the
project.</p>

<h4 class=dense>Maintenance</h4>
<p>I maintain several pipelines in the webspam group.</p>

<h5 class=dense>Surfer</h5>
<small>(August 2006 - September 2006; October 2007 - March 2009)</small>

<p>With Matt Rosencrantz, added 301 (permanent) redirect information to the
Surfer link graph analysis tool. This served as my starter project, and I've
helped MattR maintain Surfer after pushing my changes.</p>

<h5 class=dense>New Domains Feed</h5>
<small>(September, 2006 - January 2009)</small>

<p>With Evan Roseman, took control of the new domains feed from the Perfect
Crawl team and updated it to more effectively screen kited domains. In March,
2007 I took over the zonemap feed from Evan and began making improvements.</p>

<h4 class=dense>Clobber/Toolbar Bookmarks</h4>
<small>(July 2007 - December 2008)</small>

<p>
Investigated the use of user-labeled bookmarks as a sort of "virtual anchor".
This involved learning about BigTable, Kansas and Mustang. I developed a
bookmarks browser for easy searching across bookmark labels and am working on
building a parallel Mustang section with the bookmark labels.
</p>


<h5 class=dense>Commercial Queries</h5>
<small>(January 2007 - May 2007)</small>

<p>
Worked with Meenali Rungta to update/replace the four year-old Commercial Query
Detector. Developed a test harness web application to ease evaluation and
comparison of spammy query detectors. Explored word frequency on spamindexed
pages in the history project as a source of spammy phrases. This project is
currently on the backburner, but may be resumed again in the future if the need
presents itself.
</p>

<h4 class=dense>Boosting Good Sites</h4>
<small>(September 2006 - May 2007)</small>

<p>Worked with Shashi Thakur and Vineet Gupta to explore signals of site
quality. Signals explored included:
  <ul>
    <li>Multi-year registrations in whois</li>
    <li>Bookmarks (Toolbar V4, and also Google Browser Sync)</li>
    <li>Trafficrank = PageRank divided by toolbar traffic</li>
    <li>Squeal non-spam site quality ratings</li>
    <li>Domain Registrar/TLD cost</li>
    <li>Google Reader subscribers</li>
    <li>Firefox vs. IE clicks</li>
  </ul>
</p>

</div>

<h3 class=dense><a id="t_misc" onClick="return _toggleSection(this)" style="padding:0 2px 0 2px;cursor:hand;cursor:pointer;text-decoration:none;" href="#"><img src=http://www.google.com/images/triangle.gif width=11 height=11 border=0></a> Miscellaneous Projects</h3>

<div id="cq_misc" style="">
  <ul>
    <li><a href="http://oldsf.org/">OldSF.org</a>
    <li>Wikipedia XML Feed
    <li>dragtable
    <li>Distributed profiling in MapReduce
  </ul>
</div>

<div id="cp_misc" style="display:none;">
  <p>This is a smattering of internal and external/open-source projects I've
  worked on while at Google.</p>

<h4 class=dense>OldSF.org</h4>
<small>(July-August, 2011)</small>

<p>I geocoded about 13,000 images from the San Francisco Library's <a
  href="http://sfpl.org/index.php?pg=0200000301">San Francisco Historical
  Photograph Collection</a> using a <a href="http://www.oldsf.org/about">variety
  of techniques</a>. I put these on a Google Map, added a nifty time silder and
released it (with the Library's permission) to the public as <a
 href="http://oldsf.org/">oldsf.org</a>.</p>

<p>The response was overwhelmingly positive. OldSF has recieved ~100,000 visits
in its first two months and has been tweeted <a
  href="http://twitter.com/search?q=http%3A%2F%2Fwww.oldsf.org%2F">over 1,600
  times</a>. It has generated good PR for the SF Library. It's been useful to
them, too: I released all of my geocodes as a JSON file, which has allowed them
to share geocodes with other sites like <a
  href="http://historypin.com">historypin.com</a>, a Google-backed venture.
</p>

<h4 class=dense>Wikipedia</h4>
<small>(2007)</small>

<p>With Evan Martin and Daisy Stanton, developed tools to import Wikipedia's
current revision and full edit history archives and put them into a
mapreduce-able format. This has involved extensive work with borg, third-party
libraries (libxml and lzma), and gunit. These imports are used by Daffie and
Google Earth, among others.</p>

<h4 class=dense>dragtable</h4>
<small>(May-June, 2008)</small>
<p>Developed a lightweight JavaScript library for <a
  href="http://spamgeist">spamgeist</a> to let users drag table columns to
reorder them. I turned this into an open source <a
  href="http://code.google.com/p/dragtable/">project</a> and <a
  href="http://danvk.org/dragtable/">released it</a> publicly.</p>

<h4 class=dense>Distributed profiling in MapReduce</h4>
<small>(October 2008, March-June 2009)</small>
<p>Developed code to collect CPU profiles from MapReduce workers and aggregate
them in the master. Checked this in as an experimental feature in MapReduce and
sent out an email to <a
  href="https://groups.google.com/a/google.com/group/mapreduce-users/about">mapreduce-announce</a>,
which is read by ~1500 Google engineers.</p>
</div>

<h2>Significant 20% accomplishments at Google</h2>
<h3 class=dense>Sunrise/Sunset Onebox</h3>
<small>(2010, 2012)</small>
<p>In 2010, I <a
href="http://googleblog.blogspot.com/2010/06/this-week-in-search-62710.html">launched</a>
the Sunrise/Sunset onebox as a 20% project. I did all the engineering work for
this launch, from implementing the Sunrise equation in the search backends to
writing query patterns and a template for the frontend.<p>

<p>While Sunrise/Sunset was initially considered a minor feature, its popularity
has grown over time, with daily impressions increasing 10x in the first three
years since launch. It's been featured as a part of Android voice search and
extended to 40 languages. It's been used <a
href="https://x20web.corp.google.com/~danvk/no_crawl/sun/index.html">over 100
million times</a> since launch.</p>

<h3 class=dense>G%gle (Percent Server)</h3>
<small>(September 2006 - <i>present</i>)</small>
<p>As a 20% project, I developed the <a href="http://percent">http://percent</a>
server, which tells you what percentage of Googlers are newer than you.
Apparently there was great demand for this information, because it's received
approximately 500 visitors/day since I began tracking this information in late
December 2006. I've worked sporadically on percent since its launch, and have
used it to learn about core Google technologies.
Percent has slowly begun to become a part of Google culture and has sprung off
several related projects like <a href="http://go/epitaphs">epitaphs</a> and <a
  href="http://go/epigraphs">epigraphs</a>.

<p>Since it launched, percent has received over 500,000 visits and 1.4M page
views. Not bad for an internal project! It has been used by over 13,000 Googlers
(i.e. at least half the company). I've received two peer bonuses for my work on
Percent.</p>

<h3 class=dense>Shuttlesheet</h3>
<small>(September 2008, July 2009)</small>
<p>Frustrated by the Google Commuter Shuttle interface at <a
  href="http://go/shuttle">go/shuttle</a>, I created a cleaner, faster
alternative UI at <a href="http://go/shuttlesheet">go/shuttlesheet</a>. The
initial version was well-received and drew thousands of visits.</p>

<p>I launched a major overhaul in July 2009. Key new features were the ability
to access shuttle schedules from outside of VPN and an interface designed for
mobile phones. The URL changed to <a
  href="http://shuttlesheet.appspot.com/">shuttlesheet.appspot.com</a>.  I was
something of a pioneer with this change, as shuttlesheet is one of the few
Single Sign On (SSO) applications hosted using the external Google App
Engine.</p>

<p>Shuttlesheet has received over 300,000 visits since its initial launch and has
been used by over 2,000 distinct Googlers (nearly a tenth of the company!). I
have received ten peer bonuses for my work on shuttlesheet.</p>

<h2>Other Projects</h2>

<h3 class=dense>OldNYC</h3>
<small>(January 2013 - <i>present</i>)</small>
<p>See: <a href="http://oldnyc.org/">OldNYC.org</a></p>
<p>After moving to NYC, I got in touch with the NYPL about creating an "OldSF for NYC." This turned into a major project to map and transcribe their <a href="http://digitalcollections.nypl.org/collections/photographic-views-of-new-york-city-1870s-1970s-from-the-collections-of-the-ne-2#/?tab=about">Photographic Views of NYC</a> collection. After launching in mid-2015, the site was used by millions of people and received <a href="http://www.danvk.org/2015/06/04/launched-oldnyc.html">widespread media attention</a>, including a <a href="http://cityroom.blogs.nytimes.com/2015/05/26/new-york-today-new-views-of-the-past/?_r=0">write-up</a> in the Times. I <a href="http://www.nypl.org/audiovideo/oldnyc-launch-party">recorded a talk</a> about the project at the NYPL in summer 2015.</p>

<h3 class=dense>Comparea</h3>
<small>(2014)</small>
<p>See: <a href="http://comparea.org/">comparea.org</a></p>
<p>Comparea is a tool that lets you Comparea Areas. It lets you answer questions like “how big is Greenland, really?” or “how large would Alaska be if it were in the contiguous US?”. Comparea has been popular <a href="http://www.freetech4teachers.com/2014/09/three-easy-ways-to-visual-compare-sizes.html">amongst school teachers</a>. Read more about it in <a href="http://www.danvk.org/wp/2014-08-13/introducing-comparea/">this blog post</a>.

<h3 class=dense>OldSF</h3>
<small>(2008 - 2012)</small>
<p>See: <a href="http://oldsf.org/">OldSF.org</a></p>
<p>Historical photographs of San Francisco, dated, geocoded, mapped and visualized. A collaboration with the SFPL.<br>
See <a href="http://www.nytimes.com/2011/09/04/us/04bchistory.html">coverage</a> in the New York Times.</p>

<h3 class=dense>dygraphs</h3>
<small>(November 2006 - <i>present</i>)</small>
<p>See: <a href="http://dygraphs.com/">dygraphs.com</a></p>
<p>In 2006, I developed an interactive, zoomable graph for the spam dashboard to
replace the static image that had previously graced it. The new graph helped
clarify recent movements in the spam percentage and uncovered numerous
glitches in the spam metrics that might have been overlooked otherwise.</p>

<p>After joining the Yala group, I realized that my visualization library had
been <a href="http://geohistory/">useful</a> to 2/2 of my teams and hence might
have broader appeal. So I <a
  href="http://code.google.com/p/dygraphs/">open-sourced</a> it.</p>

<p>dygraphs has since developed a strong community of users, both inside and
outside of Google. It is used on <a href="http://pcon/">Monarch</a> (the
successor to borgmon) and on <a href="http://correlate/">Google Correlate</a>.
It has an active <a href="http://groups.google.com/group/dygraphs-users">mailing
  list</a> and a <a href="http://blog.dygraphs.com/">blog</a>.</p>


<h2>Education</h2>
<h3><a href="http://www.rice.edu/">Rice University</a></h3>
<ul>
<li>Bachelor of Arts, Computer Science and Mathematics, <i>cum laude</i>, 2006
(3.9 GPA).</li> <li>Recipient of the W. L. Moody Jr. Scholarship in
Engineering, 2004-2006</li>
<li>Winner of the Hubert Bray Prize in Mathematics, Spring 2005, awarded
annually to the top Junior Math major at Rice.</li>
<li>Competed in the William Lowell Putnam national math competition, 2002-2005.
Best finish was in the top 150 nationally in 2005.</li>
</ul>

<h2>Prior Work Experience</h2>
<p><i>Research Assistant, Rice University</i>, Summer 2006<br/>
Spent the summer before coming to Google analyzing the Wikipedia edit history
and attempting to write an edit classifier to detect vandalism.</p>

<p><i>Microsoft Intern</i>, Summer 2005<br/>
Software Development Engineer (SDE)
Designed and developed a new mechanism for rolling out features on the MSN
Shopping website (shopping.msn.com). Implemented this mechanism using
C#/ASP.NET and Microsoft SQL Server 2000.
</p>

<p>College Computing Associate (CCA), Fall 2004 - Spring 2006<br/>
Troubleshooted computers for over 300 students at Rice University. Extensive
work with network/wireless troubleshooting, and virus protection.</p>

</body>
</html>
